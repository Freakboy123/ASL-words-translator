{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import mediapipe as mp\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some mediapipe witchery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(video_path, video_url, class_name,start_frame, end_frame):\n",
    "    csv_file = f\"data/{class_name}/{video_url}{start_frame}.csv\"\n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    num_coords = 21 + 21 + 33\n",
    "    landmarks = ['class']\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "        \n",
    "\n",
    "\n",
    "#working with each video\n",
    "    cap = cv2.VideoCapture(os.path.join(video_path, video_url)+\".mp4\")\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    # Read until video is completed\n",
    "    else: \n",
    "        print(\"Currently working with video: \",  video_url, \" \", class_name)\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "            frameNr=0\n",
    "\n",
    "            while(cap.isOpened()):\n",
    "                frameNr+=1\n",
    "\n",
    "                if frameNr<start_frame:\n",
    "                    continue\n",
    "\n",
    "                if frameNr>end_frame:\n",
    "                    break\n",
    "                    \n",
    "                # Capture frame-by-frame\n",
    "                ret, frame = cap.read() \n",
    "                if ret == True:\n",
    "                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    image.flags.writeable = False    \n",
    "                    results = holistic.process(image)\n",
    "                    # Display the resulting frame\n",
    "                    # Right hand\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Left Hand\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Pose Detections\n",
    "                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "                    cv2.imshow('Frame',image)\n",
    "                    # Press Q on keyboard to  exit\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    # Export coordinates\n",
    "                    try:\n",
    "                        # Extract Pose landmarks\n",
    "                        if results.pose_landmarks:\n",
    "                            pose = results.pose_landmarks.landmark\n",
    "                            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                        else:\n",
    "                            return\n",
    "                            # pose_row=list(np.array([[0,0,0,0] for i in range(33)]).flatten())\n",
    "                        # Extract hands landmarks\n",
    "                        if results.right_hand_landmarks:\n",
    "                            right_hand = results.right_hand_landmarks.landmark\n",
    "                            right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no right hand detected, then it writes 0 to the CSV file\n",
    "                            right_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "                        if results.left_hand_landmarks:\n",
    "                            left_hand = results.left_hand_landmarks.landmark\n",
    "                            left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no left hand detected, then it writes 0 to the CSV file\n",
    "                            left_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "\n",
    "                        # Concate rows\n",
    "                        row = pose_row + right_hand_row + left_hand_row\n",
    "                        # Append class name \n",
    "                        row.insert(0, class_name)\n",
    "\n",
    "                        # Export to CSV\n",
    "                        with open(csv_file, mode='a', newline='') as f:\n",
    "                            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                            csv_writer.writerow(row) \n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(str(e) +\"for \", class_name, \" \", video_url )\n",
    "                        return false \n",
    "                    \n",
    "\n",
    "            \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # When everything done, release the video capture object\n",
    "            cap.release()\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single test\n",
    "#[video_path, video_url, label]\n",
    "# extract_coordinates(\"\", \"test-vid\", \"test012\", 5,6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### working with the MSASL json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>start_time</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>signer</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>height</th>\n",
       "      <th>fps</th>\n",
       "      <th>end_time</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>box</th>\n",
       "      <th>width</th>\n",
       "      <th>review</th>\n",
       "      <th>available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>ASL ABSENT</td>\n",
       "      <td>837</td>\n",
       "      <td>360</td>\n",
       "      <td>28.971</td>\n",
       "      <td>1.277</td>\n",
       "      <td>https://www.youtube.com/watch?v=ri3NrdgfAtE</td>\n",
       "      <td>absent</td>\n",
       "      <td>[0.21896389130000002, 0.008568197500000001, 0....</td>\n",
       "      <td>202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>help</td>\n",
       "      <td>help</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>help 2</td>\n",
       "      <td>50</td>\n",
       "      <td>360</td>\n",
       "      <td>29.970</td>\n",
       "      <td>3.670</td>\n",
       "      <td>www.youtube.com/watch?v=l31UXgChCS4</td>\n",
       "      <td>help</td>\n",
       "      <td>[0.0503727198, 0.2994125783, 1, 0.6968145967]</td>\n",
       "      <td>640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come on</td>\n",
       "      <td>come on</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>asl come on</td>\n",
       "      <td>889</td>\n",
       "      <td>360</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.640</td>\n",
       "      <td>https://www.youtube.com/watch?v=pt9bV_EvcaU</td>\n",
       "      <td>come on</td>\n",
       "      <td>[0.08946925400000001, 0.1794851124, 0.99899017...</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>language</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>LANGUAGE(3)</td>\n",
       "      <td>513</td>\n",
       "      <td>360</td>\n",
       "      <td>15.000</td>\n",
       "      <td>3.733</td>\n",
       "      <td>https://www.youtube.com/watch?v=-j1wozf6o9w</td>\n",
       "      <td>language</td>\n",
       "      <td>[0.1770857871, 0.0036684573, 1, 0.9955700636]</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>confused</td>\n",
       "      <td>confused</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>ASL Confused</td>\n",
       "      <td>272</td>\n",
       "      <td>360</td>\n",
       "      <td>29.969</td>\n",
       "      <td>3.170</td>\n",
       "      <td>https://www.youtube.com/watch?v=y8tHmOQcCwU</td>\n",
       "      <td>confused</td>\n",
       "      <td>[0.0626253188, 0.209987849, 1, 0.7668771744]</td>\n",
       "      <td>640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org_text clean_text  start_time  signer_id  signer  start  end  \\\n",
       "0    absent     absent         0.0        114      -1      0   37   \n",
       "1      help       help         0.0         76      42      0  110   \n",
       "2   come on    come on         0.0        114      -1      0   41   \n",
       "3  LANGUAGE   language         0.0          3      -1      0   56   \n",
       "4  confused   confused         0.0         53      -1      0   95   \n",
       "\n",
       "           file  label  height     fps  end_time  \\\n",
       "0    ASL ABSENT    837     360  28.971     1.277   \n",
       "1        help 2     50     360  29.970     3.670   \n",
       "2   asl come on    889     360  25.000     1.640   \n",
       "3   LANGUAGE(3)    513     360  15.000     3.733   \n",
       "4  ASL Confused    272     360  29.969     3.170   \n",
       "\n",
       "                                           url      text  \\\n",
       "0  https://www.youtube.com/watch?v=ri3NrdgfAtE    absent   \n",
       "1          www.youtube.com/watch?v=l31UXgChCS4      help   \n",
       "2  https://www.youtube.com/watch?v=pt9bV_EvcaU   come on   \n",
       "3  https://www.youtube.com/watch?v=-j1wozf6o9w  language   \n",
       "4  https://www.youtube.com/watch?v=y8tHmOQcCwU  confused   \n",
       "\n",
       "                                                 box  width  review  available  \n",
       "0  [0.21896389130000002, 0.008568197500000001, 0....    202     NaN      False  \n",
       "1      [0.0503727198, 0.2994125783, 1, 0.6968145967]    640     NaN       True  \n",
       "2  [0.08946925400000001, 0.1794851124, 0.99899017...    480     NaN      False  \n",
       "3      [0.1770857871, 0.0036684573, 1, 0.9955700636]    480     NaN       True  \n",
       "4       [0.0626253188, 0.209987849, 1, 0.7668771744]    640     NaN      False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(\"MSASL-combined.json\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  koMZVbqiXf4   twenty\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  o-c8ynzKI7w   dictionary\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  nDdxGqbZ79g   soup\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  xKUeV22GKb0   together\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(csv_file):\n\u001b[0;32m     31\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m extract_coordinates(video_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcombined-dataset/\u001b[39;49m\u001b[39m\"\u001b[39;49m, video_url \u001b[39m=\u001b[39;49m video_url, class_name \u001b[39m=\u001b[39;49m label, start_frame \u001b[39m=\u001b[39;49m start_frame, end_frame \u001b[39m=\u001b[39;49m end_frame):\n\u001b[0;32m     35\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39m#give the progress by every 50 videos\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 43\u001b[0m, in \u001b[0;36mextract_coordinates\u001b[1;34m(video_path, video_url, class_name, start_frame, end_frame)\u001b[0m\n\u001b[0;32m     41\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     42\u001b[0m image\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m    \n\u001b[1;32m---> 43\u001b[0m results \u001b[39m=\u001b[39m holistic\u001b[39m.\u001b[39;49mprocess(image)\n\u001b[0;32m     44\u001b[0m \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# Right hand\u001b[39;00m\n\u001b[0;32m     46\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mright_hand_landmarks, mp_holistic\u001b[39m.\u001b[39mHAND_CONNECTIONS, \n\u001b[0;32m     47\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m22\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m     48\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m44\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     49\u001b[0m                         )\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n\u001b[0;32m    161\u001b[0m   \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[0;32m    366\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(0, len(test_df)-1):\n",
    "    if test_df.loc[idx, \"available\"] == False:\n",
    "        continue\n",
    "\n",
    "    video_url = test_df.loc[idx, \"url\"][-11:]\n",
    "\n",
    "    start_frame = test_df.loc[idx, \"start\"]\n",
    "\n",
    "    end_frame = test_df.loc[idx, \"end\"]\n",
    "    \n",
    "    fps = test_df.loc[idx, \"fps\"]\n",
    "\n",
    "    label = test_df.loc[idx, \"clean_text\"]\n",
    "    str(label)\n",
    "    label = label.replace(\"/\", \" \")\n",
    "\n",
    "    if label[-1] == \" \":\n",
    "        label[:-1]\n",
    "\n",
    "\n",
    "    #creating empty folder with data\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \n",
    "    if not os.path.exists(\"data/{}\".format(label)):\n",
    "        os.makedirs(\"data/{}\".format(label))\n",
    "    \n",
    "    #creating empty file in folder, I added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    csv_file = f\"data/{label}/{video_url}{start_frame}.csv\"\n",
    "    if os.path.exists(csv_file):\n",
    "        continue\n",
    "\n",
    "\n",
    "    if not extract_coordinates(video_path = \"combined-dataset/\", video_url = video_url, class_name = label, start_frame = start_frame, end_frame = end_frame):\n",
    "        break\n",
    "    \n",
    "    #give the progress by every 50 videos\n",
    "    if idx%50==0:\n",
    "        print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-asl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17062ca204f66f718896ff35a055f4f5637bca1ea6e288aa2be1f036ecf3bc83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
