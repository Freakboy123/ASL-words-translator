{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import math\n",
    "import mediapipe as mp\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some mediapipe witchery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (3758744180.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[37], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "def extract_coordinates(video_path, video_url, class_name,start_frame, end_frame):\n",
    "\n",
    "    #creating empty folder with data\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \n",
    "    if not os.path.exists(\"data/{}\".format(class_name)):\n",
    "        os.makedirs(\"data/{}\".format(class_name))\n",
    "        \n",
    "    \n",
    "    #creating empty file in folder, I added the start_time in the name of the csv file, so that if a symbol appears many times in a video, it will still be created in two different csv files, just that they will have different starting times\n",
    "    csv_file = f\"data/{class_name}/{video_url}{start_frame}.csv\"\n",
    "    if os.path.exists(csv_file):\n",
    "        continue\n",
    "\n",
    "    with open(csv_file, mode='w', newline='') as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(landmarks)\n",
    "        \n",
    "\n",
    "# Setup CSV File for the videos\n",
    "# 21 right hand landmarks, 21 left hand landmarks, 33 pose landmarks\n",
    "    num_coords = 21 + 21 + 33\n",
    "    landmarks = ['class']\n",
    "    for val in range(1, num_coords+1):\n",
    "        landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "    print(\"Initialized an empty landmarks of size:\", len(landmarks))\n",
    "\n",
    "#working with each video\n",
    "    cap = cv2.VideoCapture(os.path.join(video_path, video_url)+\".mp4\")\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    # Read until video is completed\n",
    "    else: \n",
    "        print(\"Currently working with video: \",  video_url)\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    "            frameNr=0\n",
    "\n",
    "            while(cap.isOpened()):\n",
    "                frameNr+=1\n",
    "\n",
    "                if frameNr<start_frame:\n",
    "                    continue\n",
    "\n",
    "                if frameNr>end_frame:\n",
    "                    break\n",
    "                    \n",
    "                # Capture frame-by-frame\n",
    "                ret, frame = cap.read() \n",
    "                if ret == True:\n",
    "                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    image.flags.writeable = False    \n",
    "                    results = holistic.process(image)\n",
    "                    # Display the resulting frame\n",
    "                    # Right hand\n",
    "                    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Left Hand\n",
    "                    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "\n",
    "                    # Pose Detections\n",
    "                    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                            )\n",
    "                    cv2.imshow('Frame',image)\n",
    "                    # Press Q on keyboard to  exit\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                    # Export coordinates\n",
    "                    try:\n",
    "                        # Extract Pose landmarks\n",
    "                        pose = results.pose_landmarks.landmark\n",
    "                        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "                        # Extract hands landmarks\n",
    "                        if results.right_hand_landmarks:\n",
    "                            right_hand = results.right_hand_landmarks.landmark\n",
    "                            right_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in right_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no right hand detected, then it writes 0 to the CSV file\n",
    "                            right_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "                        if results.left_hand_landmarks:\n",
    "                            left_hand = results.left_hand_landmarks.landmark\n",
    "                            left_hand_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in left_hand]).flatten())\n",
    "                        else:\n",
    "                            #If no left hand detected, then it writes 0 to the CSV file\n",
    "                            left_hand_row = list(np.array([[0,0,0,0] for i in range(21)]).flatten())\n",
    "\n",
    "                        # Concate rows\n",
    "                        row = pose_row + right_hand_row + left_hand_row\n",
    "                        # Append class name \n",
    "                        row.insert(0, class_name)\n",
    "\n",
    "                        # Export to CSV\n",
    "                        with open(csv_file, mode='a', newline='') as f:\n",
    "                            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                            csv_writer.writerow(row) \n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "            \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # When everything done, release the video capture object\n",
    "            cap.release()\n",
    "            # Closes all the frames\n",
    "            cv2.destroyAllWindows()\n",
    "            return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  test-vid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mediapipe.python.solution_base.SolutionOutputs"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#single test\n",
    "#[video_path, video_url, label]\n",
    "# extract_coordinates(\"\", \"test-vid\", \"test012\", 5,6)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### working with the MSASL json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(\"MSASL-combined.json\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  l31UXgChCS4\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  -j1wozf6o9w\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  lsPdSIbEPSk\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  AA9_BeOYusQ\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  TR9M0q7iWxY\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  bDj1P7vz1N8\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  GDPFbcykUxg\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  1JKqWk5UeQY\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  nhEw0JSb-XQ\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  eKcf3RvzTEY\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  RcYAr8gHCoM\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  e3DdcFOB-dg\n",
      "50\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  cubfwR92E0M\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  d7DtF6u7NaA\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  lbw6sdq2XxA\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  W-OvquSQ_rM\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  r-NAg0gsgoU\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  _jv2aC-37vQ\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  Kl-MGSf9U3s\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  nfCgt2qob5g\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  SDPP_fuyuzc\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  NYiSaUJe4eU\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  koMZVbqiXf4\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  koMZVbqiXf4\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  koMZVbqiXf4\n",
      "Initialized an empty landmarks of size: 301\n",
      "Currently working with video:  koMZVbqiXf4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m label[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     18\u001b[0m     label[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 20\u001b[0m extract_coordinates(video_path \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcombined-dataset/\u001b[39;49m\u001b[39m\"\u001b[39;49m, video_url \u001b[39m=\u001b[39;49m video_url, class_name \u001b[39m=\u001b[39;49m label, start_frame \u001b[39m=\u001b[39;49m start_frame, end_frame \u001b[39m=\u001b[39;49m end_frame)\n\u001b[0;32m     21\u001b[0m \u001b[39m#give the progress by every 50 videos\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m idx\u001b[39m%\u001b[39m\u001b[39m50\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[34], line 50\u001b[0m, in \u001b[0;36mextract_coordinates\u001b[1;34m(video_path, video_url, class_name, start_frame, end_frame)\u001b[0m\n\u001b[0;32m     48\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     49\u001b[0m image\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m    \n\u001b[1;32m---> 50\u001b[0m results \u001b[39m=\u001b[39m holistic\u001b[39m.\u001b[39;49mprocess(image)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39m# Right hand\u001b[39;00m\n\u001b[0;32m     53\u001b[0m mp_drawing\u001b[39m.\u001b[39mdraw_landmarks(image, results\u001b[39m.\u001b[39mright_hand_landmarks, mp_holistic\u001b[39m.\u001b[39mHAND_CONNECTIONS, \n\u001b[0;32m     54\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m22\u001b[39m,\u001b[39m10\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[0;32m     55\u001b[0m                         mp_drawing\u001b[39m.\u001b[39mDrawingSpec(color\u001b[39m=\u001b[39m(\u001b[39m80\u001b[39m,\u001b[39m44\u001b[39m,\u001b[39m121\u001b[39m), thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, circle_radius\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     56\u001b[0m                         )\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\mediapipe\\python\\solutions\\holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NamedTuple:\n\u001b[0;32m    137\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mprocess(input_data\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m: image})\n\u001b[0;32m    161\u001b[0m   \u001b[39mif\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39mfor\u001b[39;00m landmark \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mpose_landmarks\u001b[39m.\u001b[39mlandmark:  \u001b[39m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[39m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[39m.\u001b[39mat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49mwait_until_idle()\n\u001b[0;32m    366\u001b[0m \u001b[39m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSolutionOutputs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_stream_type_info\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(0, len(test_df)-1):\n",
    "    if test_df.loc[idx, \"available\"] == False:\n",
    "        continue\n",
    "\n",
    "    video_url = test_df.loc[idx, \"url\"][-11:]\n",
    "\n",
    "    start_frame = test_df.loc[idx, \"start\"]\n",
    "\n",
    "    end_frame = test_df.loc[idx, \"end\"]\n",
    "    \n",
    "    fps = test_df.loc[idx, \"fps\"]\n",
    "\n",
    "    label = test_df.loc[idx, \"clean_text\"]\n",
    "    str(label)\n",
    "    label = label.replace(\"/\", \" \")\n",
    "\n",
    "    if label[-1] == \" \":\n",
    "        label[:-1]\n",
    "    \n",
    "    extract_coordinates(video_path = \"combined-dataset/\", video_url = video_url, class_name = label, start_frame = start_frame, end_frame = end_frame)\n",
    "    #give the progress by every 50 videos\n",
    "    if idx%50==0:\n",
    "        print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
