{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    ~copy the initial database, DON\"T MODIFY DIRECTLY.\n",
    "    *Delete videos that are not available.\n",
    "\n",
    "\n",
    "    *Process videos by cropping them based on the timestamps and rename in the the following format\n",
    "        ~Label-videoID-1\n",
    "        if there are more than 1 videos, \n",
    "        Label-videoID-2, 3, etc;\n",
    "\n",
    "\n",
    "    *Crop the width and the height of the videos based of the box coordinates provided in the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the format of the videos  I am treating\n",
    "{\"org_text\": \"emotional\", \"clean_text\": \"emotional\", \"start_time\": 0.0, \"signer_id\": 20, \"signer\": 40, \"start\": 0, \"end\": 30, \"file\": \"SignSchool Emotional\", \"label\": 907, \"height\": 360.0, \"fps\": 23.976, \"end_time\": 1.251, \"url\": \"www.youtube.com/watch?v=C59jcSo4fEI\", \"text\": \"emotional\", \"box\": [0.059554219245910645, 0.2810196578502655, 1.0, 0.8543376922607422], \"width\": 640.0},\n",
    "\n",
    "{<given-word>, <start time> <>}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the data\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(\"Datasets/MS-ASL/MS-ASL-with-new-labels/test-file.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing videos to numpy array (function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1080, 1920, 3)\n"
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39mDatasets/MS-ASL/MS-ASL-with-new-labels/test-file.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py:757\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[0;32m    756\u001b[0m \u001b[39mwith\u001b[39;00m json_reader:\n\u001b[1;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py:915\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_lines(data_lines))\n\u001b[0;32m    914\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    917\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py:937\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    935\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 937\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[0;32m    939\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1064\u001b[0m, in \u001b[0;36mParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_numpy()\n\u001b[0;32m   1063\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_no_numpy()\n\u001b[0;32m   1066\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Personnel\\Other learning\\Programming\\Personal_projects\\ASL_Language_translation\\env\\lib\\site-packages\\pandas\\io\\json\\_json.py:1321\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1317\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[0;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[1;32m-> 1321\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m     )\n\u001b[0;32m   1323\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1324\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[0;32m   1325\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[0;32m   1326\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1327\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
>>>>>>> 6415dcec884a5258618d91a5e47aacf5ec45fdfe
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
    "\n",
    "# changing an image into an array\n",
    "def change_img(image_name):\n",
    "    img = Image.open(f\"{image_name}\")\n",
    " \n",
    "    # asarray() class is used to convert\n",
    "    # PIL images into NumPy arrays\n",
    "    numpydata = asarray(img)\n",
    "    \n",
    "    # <class 'numpy.ndarray'>\n",
    "    print(type(numpydata))\n",
    "    \n",
    "    #  shape\n",
    "    print(numpydata.shape)\n",
    "\n",
    "\n",
    "change_img(\"test_frames/frame_330.jpg\")"
=======
    "test_df = pd.read_json(\"Datasets/MS-ASL/MS-ASL-with-new-labels/test-file.json\")"
>>>>>>> 6415dcec884a5258618d91a5e47aacf5ec45fdfe
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cutting the videos\n"
   ]
  },
  {
<<<<<<< HEAD
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the videos into frames.\n",
    "\n",
    "https://techtutorialsx.com/2021/04/29/python-opencv-splitting-video-frames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path='test-video2.mov'\n",
    "get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(video_path):\n",
    "    capture = cv2.VideoCapture(f\"{video_path}\")\n",
    "\n",
    "    frameNr = 0\n",
    "    # fps=int(capture.get(cv2.CAP_PROP_FRAME_COUNTCAP))\n",
    "\n",
    "    #time in seconds\n",
    "    start_time=10\n",
    "    end_time=30\n",
    "\n",
    "    #size of the image\n",
    "    # frameWidth = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    # frameHeight = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frameWidth = 500\n",
    "    frameHeight = 500\n",
    "    frameCount = (end_time-start_time)\n",
    "\n",
    "    start_frame=start_time*fps\n",
    "    end_frame=end_time*fps\n",
    "\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "    while (True):\n",
    "        \n",
    "        success, frame = capture.read()\n",
    "        # print(frameNr)\n",
    "        if success and frameNr>start_frame and frameNr<end_frame:\n",
    "            if frameNr%30==0: \n",
    "                cv2.imwrite(f'test_frames/frame_{frameNr}.jpg', frame)\n",
    "\n",
    "        #end of the video, or end of the portion of the video\n",
    "        if frameNr>end_frame:\n",
    "            break\n",
    "    \n",
    "        frameNr = frameNr+1\n",
    "        \n",
    "    \n",
    "    capture.release()"
   ]
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 6415dcec884a5258618d91a5e47aacf5ec45fdfe
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a1f3fb68dd2ba2ba2967be31133212ab5289cf599836f8f402dc82a3e66207d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
