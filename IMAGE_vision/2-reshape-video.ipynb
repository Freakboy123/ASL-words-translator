{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    ~copy the initial database, DON\"T MODIFY DIRECTLY.\n",
    "    *Delete videos that are not available.\n",
    "\n",
    "\n",
    "    *Process videos by cropping them based on the timestamps and rename in the the following format\n",
    "        ~Label-videoID-1\n",
    "        if there are more than 1 videos, \n",
    "        Label-videoID-2, 3, etc;\n",
    "\n",
    "\n",
    "    *Crop the width and the height of the videos based of the box coordinates provided in the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the format of the videos  I am treating\n",
    "{\"org_text\": \"emotional\", \"clean_text\": \"emotional\", \"start_time\": 0.0, \"signer_id\": 20, \"signer\": 40, \"start\": 0, \"end\": 30, \"file\": \"SignSchool Emotional\", \"label\": 907, \"height\": 360.0, \"fps\": 23.976, \"end_time\": 1.251, \"url\": \"www.youtube.com/watch?v=C59jcSo4fEI\", \"text\": \"emotional\", \"box\": [0.059554219245910645, 0.2810196578502655, 1.0, 0.8543376922607422], \"width\": 640.0},\n",
    "\n",
    "{<given-word>, <start time> <>}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(\"Datasets/MS-ASL/MS-ASL-with-new-labels/test-file.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changing videos to numpy array (function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# changing an image into an array\n",
    "def change_img(image_name):\n",
    "    img = Image.open(f\"{image_name}\")\n",
    " \n",
    "    # asarray() class is used to convert\n",
    "    # PIL images into NumPy arrays\n",
    "    numpydata = asarray(img)\n",
    "    \n",
    "    # <class 'numpy.ndarray'>\n",
    "    print(type(numpydata))\n",
    "    \n",
    "    #  shape\n",
    "    print(numpydata.shape)\n",
    "\n",
    "\n",
    "change_img(\"test_frames/frame_330.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cutting the videos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the videos into frames.\n",
    "\n",
    "https://techtutorialsx.com/2021/04/29/python-opencv-splitting-video-frames/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path='test-video2.mov'\n",
    "get_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(video_path):\n",
    "    capture = cv2.VideoCapture(f\"{video_path}\")\n",
    "\n",
    "    frameNr = 0\n",
    "    # fps=int(capture.get(cv2.CAP_PROP_FRAME_COUNTCAP))\n",
    "\n",
    "    #time in seconds\n",
    "    start_time=10\n",
    "    end_time=30\n",
    "\n",
    "    #size of the image\n",
    "    # frameWidth = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    # frameHeight = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frameWidth = 500\n",
    "    frameHeight = 500\n",
    "    frameCount = (end_time-start_time)\n",
    "\n",
    "    start_frame=start_time*fps\n",
    "    end_frame=end_time*fps\n",
    "\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "    while (True):\n",
    "        \n",
    "        success, frame = capture.read()\n",
    "        # print(frameNr)\n",
    "        if success and frameNr>start_frame and frameNr<end_frame:\n",
    "            if frameNr%30==0: \n",
    "                cv2.imwrite(f'test_frames/frame_{frameNr}.jpg', frame)\n",
    "\n",
    "        #end of the video, or end of the portion of the video\n",
    "        if frameNr>end_frame:\n",
    "            break\n",
    "    \n",
    "        frameNr = frameNr+1\n",
    "        \n",
    "    \n",
    "    capture.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a1f3fb68dd2ba2ba2967be31133212ab5289cf599836f8f402dc82a3e66207d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
